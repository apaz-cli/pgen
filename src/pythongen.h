#ifndef PGEN_PYTHONGEN_INCLUDE
#define PGEN_PYTHONGEN_INCLUDE

#include "ast.h"
#include <stdio.h>
#include <string.h>
#ifndef PGEN_CODEGEN_INCLUDE
#include "codegen.h"
#include <sys/stat.h>
#endif

static inline void generate_setup_script(codegen_ctx *ctx, char *setup_path) {
  FILE *setup_file = fopen(setup_path, "w");
  if (!setup_file) {
    ERROR("Could not open setup.py for writing.");
  }

  const char *setup_script =
      "from setuptools import setup, Extension\n"
      "\n"
      "# Build the generated extension, silencing warnings for valid code "
      "that\n"
      "# pgen generates and turning all other warnings into errors.\n"
      "module = Extension(\n"
      "    \"%s_parser\",\n"
      "    sources=[\"%s_ext.c\"],\n"
      "    extra_compile_args=[\n"
      "        \"-Wall\",\n"
      "        \"-Wextra\",\n"
      "        \"-Wpedantic\",\n"
      "        \"-Wno-unused-but-set-variable\",\n"
      "        \"-Wno-unused-parameter\",\n"
      "        \"-Wno-unused-variable\",\n"
      "        \"-Wno-missing-field-initializers\",\n"
      "        \"-Wconversion\",\n"
      "    ],\n"
      ")\n"
      "\n"
      "setup(\n"
      "    name=\"%s_parser\",\n"
      "    version=\"1.0\",\n"
      "    description=\"A parser for %s generated by pgen.\",\n"
      "    ext_modules=[module],\n"
      ")\n";

  fprintf(setup_file, setup_script, ctx->lower, ctx->lower, ctx->lower,
          ctx->lower);
  fclose(setup_file);
}

static inline void generate_extension_prologue(codegen_ctx *ctx,
                                               FILE *ext_file) {
  fprintf(ext_file, "#define PY_SSIZE_T_CLEAN\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "#if __has_include(<Python.h>)\n");
  fprintf(ext_file, "#include <Python.h>\n");
  fprintf(ext_file, "#else\n");
  fprintf(ext_file, "#include <python3.11/Python.h> // linter\n");
  fprintf(ext_file, "#endif\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "#include <stdint.h>\n");
  fprintf(ext_file, "#include <stdio.h>\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "#include \"%s.h\"\n", ctx->lower);
  fprintf(ext_file, "\n");
  fprintf(ext_file, "_Static_assert(sizeof(int32_t) == sizeof(int), \"int32_t "
                    "is not int\");\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "static PyObject *ast_to_python_dict(%s_astnode_t *node) {\n",
          ctx->lower);
  fprintf(ext_file, "  if (!node)\n");
  fprintf(ext_file, "    Py_RETURN_NONE;\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file,
          "  // Create a Python dictionary to hold the AST node data\n");
  fprintf(ext_file, "  PyObject *dict = PyDict_New();\n");
  fprintf(ext_file, "  if (!dict)\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Add kind to the dictionary\n");
  fprintf(ext_file, "  const char *kind_str = %s_nodekind_name[node->kind];\n",
          ctx->lower);
  fprintf(ext_file,
          "  PyObject *kind = PyUnicode_InternFromString(kind_str);\n");
  fprintf(ext_file, "  if (!kind) {\n");
  fprintf(ext_file, "    Py_DECREF(dict);\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "  PyDict_SetItemString(dict, \"kind\", kind);\n");
  fprintf(ext_file, "  Py_DECREF(kind);\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Convert codepoint array to Python string\n");
  fprintf(ext_file, "  PyObject *tok_repr_str = PyUnicode_FromKindAndData(\n");
  fprintf(ext_file, "      PyUnicode_4BYTE_KIND, node->tok_repr, "
                    "(ssize_t)node->repr_len);\n");
  fprintf(ext_file, "  if (!tok_repr_str) {\n");
  fprintf(ext_file, "    Py_DECREF(dict);\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file,
          "  PyDict_SetItemString(dict, \"tok_repr\", tok_repr_str);\n");
  fprintf(ext_file, "  Py_DECREF(tok_repr_str);\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Add children to the dictionary\n");
  fprintf(ext_file,
          "  PyObject *children_list = PyList_New(node->num_children);\n");
  fprintf(ext_file, "  if (!children_list) {\n");
  fprintf(ext_file, "    Py_DECREF(dict);\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "  for (uint16_t i = 0; i < node->num_children; i++) {\n");
  fprintf(ext_file,
          "    PyObject *child = ast_to_python_dict(node->children[i]);\n");
  fprintf(ext_file, "    if (!child) {\n");
  fprintf(ext_file, "      Py_DECREF(children_list);\n");
  fprintf(ext_file, "      Py_DECREF(dict);\n");
  fprintf(ext_file, "      return NULL;\n");
  fprintf(ext_file, "    }\n");
  fprintf(ext_file,
          "    PyList_SetItem(children_list, (Py_ssize_t)i, child);\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file,
          "  PyDict_SetItemString(dict, \"children\", children_list);\n");
  fprintf(ext_file, "  Py_DECREF(children_list);\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file,
          "  // TODO: Add other items to the node. Extension point.\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  return dict;\n");
  fprintf(ext_file, "}\n");
  fprintf(ext_file, "\n");
}

static inline void generate_extension_rule_binding(codegen_ctx *ctx,
                                                   FILE *ext_file,
                                                   char *rulename) {

  fprintf(ext_file,
          "static PyObject *%s_ext_parse_%s(PyObject *self, "
          "PyObject *args) {\n",
          ctx->lower, rulename);
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Extract args\n");
  fprintf(ext_file, "  const char *input_str;\n");
  fprintf(ext_file, "  size_t input_len;\n");
  fprintf(ext_file,
          "  if (!PyArg_ParseTuple(args, \"s#\", &input_str, &input_len)) {\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Convert input string to UTF-32 codepoints\n");
  fprintf(ext_file, "  codepoint_t *cps = NULL;\n");
  fprintf(ext_file, "  size_t cpslen = 0;\n");
  fprintf(
      ext_file,
      "  if (!UTF8_decode((char *)input_str, input_len, &cps, &cpslen)) {\n");
  fprintf(ext_file, "    PyErr_SetString(PyExc_RuntimeError, \"Could not "
                    "decode to UTF32.\");\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Initialize tokenizer\n");
  fprintf(ext_file, "  %s_tokenizer tokenizer;\n", ctx->lower);
  fprintf(ext_file, "  %s_tokenizer_init(&tokenizer, cps, cpslen);\n",
          ctx->lower);
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Token list\n");
  fprintf(ext_file, "  static const size_t initial_cap = 4096 * 8;\n");
  fprintf(ext_file, "  struct {\n");
  fprintf(ext_file, "    %s_token *buf;\n", ctx->lower);
  fprintf(ext_file, "    size_t size;\n");
  fprintf(ext_file, "    size_t cap;\n");
  fprintf(ext_file,
          "  } toklist = {(%s_token *)malloc(sizeof(%s_token) * "
          "initial_cap), 0, initial_cap};\n",
          ctx->lower, ctx->lower);
  fprintf(ext_file, "  if (!toklist.buf) {\n");
  fprintf(ext_file, "    free(cps);\n");
  fprintf(ext_file, "    PyErr_SetString(PyExc_RuntimeError, \"Out of memory "
                    "allocating token list.\");\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Parse tokens\n");
  fprintf(ext_file, "  %s_token tok;\n", ctx->lower);
  fprintf(ext_file, "  do {\n");
  fprintf(ext_file, "    tok = %s_nextToken(&tokenizer);\n", ctx->lower);
  fprintf(ext_file, "    if (!(tok.kind == %s_TOK_STREAMEND", ctx->upper);

  for (size_t i = 0; i < ctx->tok_kind_names.len; i++) {
    // If it's an ignored token, generate the stop token.
    int found_ignored = 0;
    for (size_t j = 0; j < ctx->directives.len; j++) {
      ASTNode *directive = ctx->directives.buf[j];
      ASTNode *li = directive->children[0];
      char *dir_name = (char *)li->extra;
      if (!strcmp(dir_name, "ignore")) {
        char *contents = (char *)directive->extra;
        // Replace all commas with spaces.
        for (size_t i = 0; i < strlen(contents); i++) {
          if (contents[i] == ',')
            contents[i] = ' ';
        }

        // Try to find the token in the contents.
        char *extra = NULL;
        char *token = strtok_r(contents, " ", &extra);
        while (token) {
          if (!strcmp(ctx->tok_kind_names.buf[i], token)) {
            found_ignored = 1;
            break;
          }
          token = strtok_r(NULL, " ", &extra);
        }
      }
    }

    if (!found_ignored)
      continue;

    fprintf(ext_file, " || tok.kind == %s_TOK_%s", ctx->upper,
            ctx->tok_kind_names.buf[i]);
  }
  fprintf(ext_file, ")) {\n");
  fprintf(ext_file, "      if (toklist.size == toklist.cap) {\n");
  fprintf(ext_file, "        toklist.buf = realloc(toklist.buf, toklist.cap *= 2);\n");
  fprintf(ext_file, "        if (!toklist.buf) {\n");
  fprintf(ext_file, "          free(cps);\n");
  fprintf(ext_file, "          PyErr_SetString(PyExc_RuntimeError,\n");
  fprintf(ext_file, "                          \"Out of memory reallocating token list.\");\n");
  fprintf(ext_file, "          return NULL;\n");
  fprintf(ext_file, "        }\n");
  fprintf(ext_file, "      }\n");
  fprintf(ext_file, "      toklist.buf[toklist.size++] = tok;\n");
  fprintf(ext_file, "    }\n");
  fprintf(ext_file, "  } while (tok.kind != %s_TOK_STREAMEND);\n", ctx->upper);
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Initialize parser\n");
  fprintf(ext_file, "  pgen_allocator allocator = pgen_allocator_new();\n");
  fprintf(ext_file, "  %s_parser_ctx parser;\n", ctx->lower);
  fprintf(ext_file, "  %s_parser_ctx_init(&parser, &allocator, toklist.buf, toklist.size);\n", ctx->lower);
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Parse AST\n");
  fprintf(ext_file, "  %s_astnode_t *ast = %s_parse_%s(&parser);\n", ctx->lower, ctx->lower, rulename);
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Create result dictionary\n");
  fprintf(ext_file, "  PyObject *result_dict = PyDict_New();\n");
  fprintf(ext_file, "  if (!result_dict) {\n");
  fprintf(ext_file, "    pgen_allocator_destroy(&allocator);\n");
  fprintf(ext_file, "    free(toklist.buf);\n");
  fprintf(ext_file, "    free(cps);\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Convert AST to Python dictionary\n");
  fprintf(ext_file, "  PyObject *ast_dict = ast_to_python_dict(ast);\n");
  fprintf(ext_file, "  PyDict_SetItemString(result_dict, \"ast\", ast_dict ? ast_dict : Py_None);\n");
  fprintf(ext_file, "  Py_XDECREF(ast_dict);\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Create error list\n");
  fprintf( ext_file, "  PyObject *error_list = PyList_New((Py_ssize_t)parser.num_errors);\n");
  fprintf(ext_file, "  if (!error_list) {\n");
  fprintf(ext_file, "    Py_DECREF(result_dict);\n");
  fprintf(ext_file, "    pgen_allocator_destroy(&allocator);\n");
  fprintf(ext_file, "    free(toklist.buf);\n");
  fprintf(ext_file, "    free(cps);\n");
  fprintf(ext_file, "    return NULL;\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "  char *err_sev_str[] = {\"info\", \"warning\", \"error\", \"fatal\"};\n");
  fprintf(ext_file, "  for (size_t i = 0; i < parser.num_errors; i++) {\n");
  fprintf(ext_file, "    %s_parse_err error = parser.errlist[i];\n", ctx->lower);
  fprintf(ext_file, "    PyObject *error_dict = PyDict_New();\n");
  fprintf(ext_file, "    if (!error_dict) {\n");
  fprintf(ext_file, "      Py_DECREF(result_dict);\n");
  fprintf(ext_file, "      Py_DECREF(error_list);\n");
  fprintf(ext_file, "      pgen_allocator_destroy(&allocator);\n");
  fprintf(ext_file, "      free(toklist.buf);\n");
  fprintf(ext_file, "      free(cps);\n");
  fprintf(ext_file, "      return NULL;\n");
  fprintf(ext_file, "    }\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "    // Set error info\n");
  fprintf(ext_file, "    PyDict_SetItemString(error_dict, \"msg\", PyUnicode_FromString(error.msg));\n");
  fprintf(ext_file, "    PyDict_SetItemString(\n");
  fprintf(ext_file, "        error_dict, \"severity\",\n");
  fprintf(ext_file, "        PyUnicode_InternFromString(err_sev_str[error.severity]));\n");
  fprintf(ext_file, "    PyDict_SetItemString(error_dict, \"line\", PyLong_FromSize_t(error.line));\n");
  fprintf(ext_file, "    PyDict_SetItemString(error_dict, \"col\", PyLong_FromSize_t(error.col));\n");
  fprintf(ext_file, "    PyList_SetItem(error_list, (Py_ssize_t)i, error_dict);\n");
  fprintf(ext_file, "  }\n");
  fprintf(ext_file, "  PyDict_SetItemString(result_dict, \"error_list\", error_list);\n");
  fprintf(ext_file, "  Py_DECREF(error_list);\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  // Clean up\n");
  fprintf(ext_file, "  pgen_allocator_destroy(&allocator);\n");
  fprintf(ext_file, "  free(toklist.buf);\n");
  fprintf(ext_file, "  free(cps);\n");
  fprintf(ext_file, "\n");
  fprintf(ext_file, "  return result_dict;\n");
  fprintf(ext_file, "}\n");
  fprintf(ext_file, "\n");
}

static inline void generate_extension_rule_bindings(codegen_ctx *ctx,
                                                    FILE *ext_file) {
  for (size_t i = 0; i < ctx->definitions.len; i++) {
    ASTNode *rule = ctx->definitions.buf[i];
    ASTNode *li = rule->children[0];
    char *rulename = (char *)li->extra;

    generate_extension_rule_binding(ctx, ext_file, rulename);
  }

  // Generate PyMethodDef
  fprintf(ext_file, "static PyMethodDef %s_methods[] = {\n", ctx->lower);

  for (size_t i = 0; i < ctx->definitions.len; i++) {
    ASTNode *rule = ctx->definitions.buf[i];
    ASTNode *li = rule->children[0];
    char *rulename = (char *)li->extra;

    fprintf(ext_file,
            "    {\"parse_%s\", %s_ext_parse_%s, METH_VARARGS, \"Parse a %s "
            "and return the AST.\"},\n",
            rulename, ctx->lower, rulename, rulename);
  }
  fprintf(ext_file, "    {NULL, NULL, 0, NULL}\n");
  fprintf(ext_file, "};\n");
  fprintf(ext_file, "\n");
}

static inline void generate_extension_def(codegen_ctx *ctx, FILE *ext_file) {

  fprintf(ext_file,
          "static struct PyModuleDef %smodule = "
          "{PyModuleDef_HEAD_INIT, \"%sparser\", NULL, -1, %s_methods};\n",
          ctx->lower, ctx->lower, ctx->lower);
  fprintf(ext_file, "\n");
  fprintf(ext_file,
          "PyMODINIT_FUNC PyInit_%s_parser(void) { return "
          "PyModule_Create(&%smodule); }\n",
          ctx->lower, ctx->lower);
}

static inline void generate_python_extension(codegen_ctx *ctx, char *ext_path) {
  FILE *ext_file = fopen(ext_path, "w");
  if (!ext_file)
    ERROR("Could not open %s for writing.", ext_path);

  generate_extension_prologue(ctx, ext_file);
  generate_extension_rule_bindings(ctx, ext_file);
  generate_extension_def(ctx, ext_file);
  fclose(ext_file);
}

static inline void generate_python_module(codegen_ctx *ctx) {
  // If we aren't generating a python module, return.
  // Otherwise initializing the codegen_ctx will already
  // have made sure the folder exists, and made sure the
  // parser header file is generated into it.
  char *module_folder = ctx->args->pythonTarget;
  if (!module_folder)
    return;

  // Write module/setup.py
  const char *setup_path = "setup.py";
  char *write_path =
      (char *)malloc(strlen(module_folder) + 1 + strlen(setup_path) + 1);
  if (!write_path)
    OOM();
  write_path[0] = '\0';
  strcat(write_path, module_folder);
  if (write_path[strlen(module_folder) - 1] != '/')
    strcat(write_path, "/");
  strcat(write_path, setup_path);
  generate_setup_script(ctx, write_path);
  free(write_path);

  // Write module/%s_ext.c
  const char *ext_path = "_ext.c";
  char *extension_path =
      (char *)malloc(strlen(module_folder) + 1 + strlen(ctx->lower) +
                     strlen(extension_path) + 1);
  if (!extension_path)
    OOM();
  extension_path[0] = '\0';
  strcat(extension_path, module_folder);
  if (extension_path[strlen(module_folder) - 1] != '/')
    strcat(extension_path, "/");
  strcat(extension_path, ctx->lower);
  strcat(extension_path, ext_path);
  generate_python_extension(ctx, extension_path);
  free(extension_path);
}

#endif /* PGEN_PTHONGEN_INCLUDE */